from fastapi import UploadFile, HTTPException
from google.cloud import storage
import pandas as pd
import zipfile
from io import BytesIO, StringIO

def read_gcs_csv(bucket_name: str, file_name: str):
    """
    å¾ GCS bucket ä¸‹è¼‰æŒ‡å®šçš„ CSV æª”ä¸¦è½‰æˆ pandas DataFrameã€‚
    å›å‚³ DataFrameã€‚
    """
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(file_name)

    # ä¸‹è¼‰æª”æ¡ˆæˆè¨˜æ†¶é«”ç‰©ä»¶
    data = blob.download_as_bytes()
    df = pd.read_csv(BytesIO(data))
    return df

BUCKET_NAME_SOURCE = "urban-computing-self-data-raw"
BUCKET_NAME_DEST = "urban-computing-self-data-processed"
OUTPUT_PATH = "merged.csv"

def process_zip_file(file: UploadFile, storage_client: storage.Client) -> str:
    """
    è™•ç†å–®ä¸€ ZIP æª”æ¡ˆï¼š
    1. é©—è­‰æ ¼å¼èˆ‡æª”å
    2. ä½¿ç”¨è¨˜æ†¶é«”å…§çš„ ZIP å…§å®¹è§£æ
    3. åˆ†æã€èåˆå£“åŠ›è³‡æ–™
    4. ä¸Šå‚³åŸ ZIP + merged.csv åˆ° GCS
    """

    # é©—è­‰æ ¼å¼
    if not file.filename.endswith(".zip"):
        raise HTTPException(status_code=400, detail=f"{file.filename} is not a .zip file")

    # æ¸…ç†æª”åï¼ˆå»é™¤é–‹é ­ç©ºç™½ã€å–ä»£ä¸­é–“ç©ºç™½ï¼‰
    new_name = file.filename.lstrip().replace(" ", "_")
    print(f"ğŸ“¦ Processing ZIP: {new_name}")

    # åˆå§‹åŒ– GCS bucket
    bucket_source = storage_client.bucket(BUCKET_NAME_SOURCE)
    bucket_dest = storage_client.bucket(BUCKET_NAME_DEST)
    blob = bucket_source.blob(new_name)

    # æª¢æŸ¥æ˜¯å¦é‡è¤‡
    if blob.exists():
        print(f"âš ï¸ File already exists: {new_name}")
        raise HTTPException(status_code=409, detail=f"File '{new_name}' already exists in {BUCKET_NAME_SOURCE}")

    # å°‡ä¸Šå‚³çš„ ZIP è®€å…¥è¨˜æ†¶é«”
    file.file.seek(0)
    zip_bytes = file.file.read()

    try:
        zf = zipfile.ZipFile(BytesIO(zip_bytes))
        nameList = zf.namelist()
        print(f"ğŸ” ZIP Content: {nameList}")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid ZIP file: {e}")

    # é©—è­‰å¿…éœ€çš„æª”æ¡ˆ
    if "Raw Data.csv" not in nameList or "meta/time.csv" not in nameList:
        raise HTTPException(status_code=400, detail=f"{file.filename} missing required files (Raw Data.csv or meta/time.csv)")

    # è®€å– meta/time.csv
    try:
        df_meta = pd.read_csv(zf.open("meta/time.csv"))
        start_row = df_meta[df_meta["event"] == "START"].iloc[0]
        start_system_time = float(start_row["system time"])
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error reading meta/time.csv: {e}")

    # è®€å– Raw Data.csv
    try:
        df_raw = pd.read_csv(zf.open("Raw Data.csv"))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error reading Raw Data.csv: {e}")

    # æ‰¾å‡ºæ™‚é–“èˆ‡å£“åŠ›æ¬„ä½
    time_col = [c for c in df_raw.columns if "time" in c.lower()][0]
    pressure_col = [c for c in df_raw.columns if "press" in c.lower()][0]

    # è™•ç†è³‡æ–™
    df_raw["Time"] = df_raw[time_col] + start_system_time
    df_raw["Pressure"] = df_raw[pressure_col]
    df_merged = df_raw[["Time", "Pressure"]].copy().sort_values("Time")

    # è‹¥ merged.csv å·²å­˜åœ¨ â†’ åˆä½µ
    output_blob = bucket_dest.blob(OUTPUT_PATH)
    if output_blob.exists():
        old_text = output_blob.download_as_text()
        df_old = pd.read_csv(StringIO(old_text))
        df_merged = pd.concat([df_old, df_merged], ignore_index=True)
        df_merged.drop_duplicates(subset=["Time"], inplace=True)
        df_merged.sort_values("Time", inplace=True)
        print(f"ğŸ§© Merged with existing data â†’ {len(df_merged)} rows")

    # âœ… ä¸Šå‚³ ZIPï¼ˆä¿ç•™åŸå§‹æª”æ¡ˆï¼‰
    blob.upload_from_string(zip_bytes, content_type="application/zip")
    print(f"âœ… Uploaded raw ZIP to gs://{BUCKET_NAME_SOURCE}/{new_name}")

    # âœ… ä¸Šå‚³æ›´æ–°å¾Œçš„ merged.csv
    csv_bytes = df_merged.to_csv(index=False, float_format="%.6f").encode("utf-8")
    output_blob.upload_from_string(csv_bytes, content_type="text/csv")
    print(f"âœ… Updated merged.csv ({len(df_merged)} rows)")

    return file.filename